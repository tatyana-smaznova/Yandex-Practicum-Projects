{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала необходимо импортировать инструменты для работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь прочитаем файл и созраним его в переменной df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим общую информацию о файле."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем на экран первые и последние строки таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "0                0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1                1  D'aww! He matches this background colour I'm s...      0\n",
       "2                2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3                3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4                4  You, sir, are my hero. Any chance you remember...      0\n",
       "...            ...                                                ...    ...\n",
       "159287      159446  \":::::And for the second time of asking, when ...      0\n",
       "159288      159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289      159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290      159449  And it looks like it was actually you who put ...      0\n",
       "159291      159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим есть ли в датасете дубликаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим баланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо сбалансировать классы перед обучением модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим соотношение классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.841344371679229"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_ratio = df['toxic'].value_counts()[0] / df['toxic'].value_counts()[1]\n",
    "class_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизируем текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    text = text.lower()\n",
    "    lemm_text = \"\".join(lemmatizer.lemmatize(text))\n",
    "    cleared_text = re.sub(r'[^a-zA-Z]', ' ', lemm_text) \n",
    "    return \" \".join(cleared_text.split())\n",
    "\n",
    "df['lemm_text'] = df['text'].apply(lemmatize_text)\n",
    "\n",
    "df = df.drop(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "\n",
    "Итак, мы прочитали данные и сохранили их в переменной df, выяснили, что пропуски и дубликаты отсутствуют, лемматизировали данные, подготовив их для дальнейшей работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим признаки для обучения и целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['toxic']\n",
    "features = df.drop(['toxic'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разделим выборку на обучающую и валидационную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь валидационную выборку разделим на валидационную и тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_valid, target_valid, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим стоп-слова, трансформируем выборки и оценим их размеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119469, 142039)\n",
      "(19911, 142039)\n",
      "(19912, 142039)\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "features_train = count_tf_idf.fit_transform(features_train['lemm_text'].values)\n",
    "features_valid = count_tf_idf.transform(features_valid['lemm_text'].values)\n",
    "features_test = count_tf_idf.transform(features_test['lemm_text'].values)\n",
    "print(features_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим классификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на CV 0.6659771337138358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "classificator = LogisticRegression()\n",
    "train_f1 = cross_val_score(classificator, \n",
    "                      features_train, \n",
    "                      target_train,\n",
    "                      cv=2,\n",
    "                      scoring='f1').mean()\n",
    "print('F1 на CV', train_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшим вес классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на CV сo cбалансированными классами 0.7510089518190128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "dict_classes={0:1, 1:class_ratio}\n",
    "classificator = LogisticRegression(class_weight=dict_classes)\n",
    "train_f1_ballanced = cross_val_score(classificator, \n",
    "                                    features_train, \n",
    "                                    target_train,\n",
    "                                    cv=2,\n",
    "                                    scoring='f1').mean()\n",
    "print('F1 на CV сo cбалансированными классами', train_f1_ballanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь повторим операцию, но со сбалансированными данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на CV со сбалансированными классами 0.7510089518190128\n"
     ]
    }
   ],
   "source": [
    "classificator = LogisticRegression(class_weight='balanced')\n",
    "train_f1_balanced = cross_val_score(classificator, \n",
    "                                    features_train, \n",
    "                                    target_train,\n",
    "                                    cv=2,\n",
    "                                    scoring='f1').mean()\n",
    "print('F1 на CV со сбалансированными классами', train_f1_ballanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдём к обучению моделей, для начала используем логистическую регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'class_weight': {0: 1, 1: 8.841344371679229}, 'solver': 'lbfgs'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.708359 for {'C': 0.1, 'class_weight': {0: 1, 1: 8.841344371679229}, 'solver': 'newton-cg'}\n",
      "0.708333 for {'C': 0.1, 'class_weight': {0: 1, 1: 8.841344371679229}, 'solver': 'lbfgs'}\n",
      "0.708303 for {'C': 0.1, 'class_weight': {0: 1, 1: 8.841344371679229}, 'solver': 'liblinear'}\n",
      "0.751009 for {'C': 1, 'class_weight': {0: 1, 1: 8.841344371679229}, 'solver': 'newton-cg'}\n",
      "0.751009 for {'C': 1, 'class_weight': {0: 1, 1: 8.841344371679229}, 'solver': 'lbfgs'}\n",
      "0.751009 for {'C': 1, 'class_weight': {0: 1, 1: 8.841344371679229}, 'solver': 'liblinear'}\n",
      "0.757531 for {'C': 10, 'class_weight': {0: 1, 1: 8.841344371679229}, 'solver': 'newton-cg'}\n",
      "0.757626 for {'C': 10, 'class_weight': {0: 1, 1: 8.841344371679229}, 'solver': 'lbfgs'}\n",
      "0.757531 for {'C': 10, 'class_weight': {0: 1, 1: 8.841344371679229}, 'solver': 'liblinear'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "classificator = LogisticRegression()\n",
    "hyperparams = [{'solver':['newton-cg', 'lbfgs', 'liblinear'],\n",
    "                'C':[0.1, 1, 10],\n",
    "                'class_weight':[dict_classes]}]\n",
    "\n",
    "clf = GridSearchCV(classificator, hyperparams, scoring='f1',cv=2)\n",
    "clf.fit(features_train, target_train)\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "LR_best_params = clf.best_params_\n",
    "print(LR_best_params)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.6f for %r\"% (mean, params))\n",
    "print()\n",
    "\n",
    "cv_f1_LR = max(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим значение F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на cv 0.7576258168136949\n",
      "F1 на валидации 0.7875432525951558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "classificator = LogisticRegression()\n",
    "classificator.set_params(**LR_best_params)\n",
    "classificator.fit(features_train, target_train)\n",
    "target_predict = classificator.predict(features_valid)\n",
    "valid_f1_LR = f1_score(target_valid, target_predict)\n",
    "print('F1 на cv', cv_f1_LR)\n",
    "print('F1 на валидации', valid_f1_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель дерева решений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 96, 'random_state': 12345}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.622736 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 50, 'random_state': 12345}\n",
      "0.618631 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 52, 'random_state': 12345}\n",
      "0.612283 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 54, 'random_state': 12345}\n",
      "0.617717 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 56, 'random_state': 12345}\n",
      "0.618584 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 58, 'random_state': 12345}\n",
      "0.622436 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 60, 'random_state': 12345}\n",
      "0.623074 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 62, 'random_state': 12345}\n",
      "0.627801 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 64, 'random_state': 12345}\n",
      "0.632404 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 66, 'random_state': 12345}\n",
      "0.631727 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 68, 'random_state': 12345}\n",
      "0.634238 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 70, 'random_state': 12345}\n",
      "0.631303 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 72, 'random_state': 12345}\n",
      "0.630737 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 74, 'random_state': 12345}\n",
      "0.631203 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 76, 'random_state': 12345}\n",
      "0.632424 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 78, 'random_state': 12345}\n",
      "0.631615 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 80, 'random_state': 12345}\n",
      "0.632726 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 82, 'random_state': 12345}\n",
      "0.634758 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 84, 'random_state': 12345}\n",
      "0.630687 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 86, 'random_state': 12345}\n",
      "0.632884 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 88, 'random_state': 12345}\n",
      "0.632484 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 90, 'random_state': 12345}\n",
      "0.633376 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 92, 'random_state': 12345}\n",
      "0.632833 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 94, 'random_state': 12345}\n",
      "0.638478 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 96, 'random_state': 12345}\n",
      "0.636491 for {'class_weight': {0: 1, 1: 8.841344371679229}, 'max_depth': 98, 'random_state': 12345}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classificator = DecisionTreeClassifier()\n",
    "hyperparams = [{'max_depth':[x for x in range(50,100,2)],\n",
    "                'random_state':[12345],\n",
    "                'class_weight':[dict_classes]}]\n",
    "\n",
    "clf = GridSearchCV(classificator, hyperparams, scoring='f1',cv=2)\n",
    "clf.fit(features_train, target_train)\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "DTC_best_params = clf.best_params_\n",
    "print(DTC_best_params)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.6f for %r\"% (mean, params))\n",
    "print()\n",
    "\n",
    "cv_f1_DTC = max(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим значение F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на cv 0.6384777023572714\n",
      "F1 на валидации 0.6530889341479973\n"
     ]
    }
   ],
   "source": [
    "classificator = DecisionTreeClassifier()\n",
    "classificator.set_params(**DTC_best_params)\n",
    "classificator.fit(features_train, target_train)\n",
    "target_predict = classificator.predict(features_valid)\n",
    "valid_f1_DTC = f1_score(target_valid, target_predict)\n",
    "print('F1 на cv', cv_f1_DTC)\n",
    "print('F1 на валидации', valid_f1_DTC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим модель CatBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на cv 0.72007995721569\n",
      "F1 на валидации 0.7687927107061503\n"
     ]
    }
   ],
   "source": [
    "classificator = CatBoostClassifier(verbose=False, iterations=250)\n",
    "classificator.fit(features_train, target_train)\n",
    "target_predict = classificator.predict(features_valid)\n",
    "cv_f1_CBC = cross_val_score(classificator,\n",
    "                                         features_train, \n",
    "                                         target_train, \n",
    "                                         cv=2, \n",
    "                                         scoring='f1').mean()\n",
    "valid_f1_CBC = f1_score(target_valid, target_predict)\n",
    "print('F1 на cv', cv_f1_CBC)\n",
    "print('F1 на валидации', valid_f1_CBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "\n",
    "Мы разделили данные на обучающую, валидационную и тестовую и обучили три модели. Далее мы соберём показатели меры F1 в таблицу, чтобы сделать выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберём показатели меры F1 в таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 на CV</th>\n",
       "      <th>F1 на валидации</th>\n",
       "      <th>Соответствие метрики</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.757626</td>\n",
       "      <td>0.787543</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.638478</td>\n",
       "      <td>0.653089</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.720080</td>\n",
       "      <td>0.768793</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        F1 на CV  F1 на валидации  Соответствие метрики\n",
       "LogisticRegression      0.757626         0.787543                  True\n",
       "DecisionTreeClassifier  0.638478         0.653089                 False\n",
       "CatBoostClassifier      0.720080         0.768793                  True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = ['LogisticRegression',\n",
    "         'DecisionTreeClassifier',\n",
    "         'CatBoostClassifier']\n",
    "data = {'F1 на CV':[cv_f1_LR,\n",
    "                    cv_f1_DTC,\n",
    "                    cv_f1_CBC],\n",
    "        'F1 на валидации':[valid_f1_LR,\n",
    "                           valid_f1_DTC,\n",
    "                           valid_f1_CBC]}\n",
    "\n",
    "scores_data = pd.DataFrame(data=data, index=index)\n",
    "scores_data['Соответствие метрики'] = scores_data['F1 на валидации'] > 0.75\n",
    "scores_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что решающее дерево не подходит под условия проекта. Самый хороший резуультат показала модель логистической регрессии. Проверим её на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тесте 0.7593913456966238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "classificator = LogisticRegression()\n",
    "best_params = [{'solver' : ['lbfgs'], 'C' : [10], 'class_weight': [{0: 1, 1: 8.841344371679229}]}]\n",
    "clf = GridSearchCV(classificator, best_params, scoring='f1',cv=2)\n",
    "\n",
    "clf.fit(features_train, target_train)\n",
    "target_predict = clf.predict(features_test)\n",
    "test_f1_LR = f1_score(target_test, target_predict)\n",
    "print('F1 на тесте', test_f1_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "\n",
    "Мы обучили и сравнили их показатели. Модель логистической регрессии, которая показала самый лучший результат, проверили на тестовой выборке, но значение получилось 0.71, что не удовлетворяет условиям проекта."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 10578,
    "start_time": "2022-09-07T19:04:20.690Z"
   },
   {
    "duration": 12999,
    "start_time": "2022-09-07T19:12:56.269Z"
   },
   {
    "duration": 110,
    "start_time": "2022-09-07T19:13:29.570Z"
   },
   {
    "duration": 15,
    "start_time": "2022-09-07T19:16:24.968Z"
   },
   {
    "duration": 9,
    "start_time": "2022-09-07T19:21:10.714Z"
   },
   {
    "duration": 239,
    "start_time": "2022-09-07T19:25:57.849Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-07T19:31:49.615Z"
   },
   {
    "duration": 1612,
    "start_time": "2022-09-08T18:00:46.234Z"
   },
   {
    "duration": 2323,
    "start_time": "2022-09-08T18:00:47.848Z"
   },
   {
    "duration": 30,
    "start_time": "2022-09-08T18:00:50.173Z"
   },
   {
    "duration": 24,
    "start_time": "2022-09-08T18:00:50.206Z"
   },
   {
    "duration": 211,
    "start_time": "2022-09-08T18:00:50.231Z"
   },
   {
    "duration": 5,
    "start_time": "2022-09-08T18:00:50.443Z"
   },
   {
    "duration": 109,
    "start_time": "2022-09-08T18:00:58.817Z"
   },
   {
    "duration": 10,
    "start_time": "2022-09-08T18:01:17.234Z"
   },
   {
    "duration": 6045,
    "start_time": "2022-09-08T18:01:22.592Z"
   },
   {
    "duration": 10,
    "start_time": "2022-09-08T18:01:35.832Z"
   },
   {
    "duration": 10,
    "start_time": "2022-09-08T18:02:15.996Z"
   },
   {
    "duration": 25,
    "start_time": "2022-09-08T18:02:18.131Z"
   },
   {
    "duration": 10,
    "start_time": "2022-09-08T18:02:18.905Z"
   },
   {
    "duration": 9,
    "start_time": "2022-09-08T18:02:22.091Z"
   },
   {
    "duration": 146,
    "start_time": "2022-09-08T18:02:41.885Z"
   },
   {
    "duration": 9,
    "start_time": "2022-09-08T18:02:52.783Z"
   },
   {
    "duration": 1407,
    "start_time": "2022-09-08T18:08:11.640Z"
   },
   {
    "duration": 751,
    "start_time": "2022-09-08T18:08:13.048Z"
   },
   {
    "duration": 34,
    "start_time": "2022-09-08T18:08:13.801Z"
   },
   {
    "duration": 13,
    "start_time": "2022-09-08T18:08:13.837Z"
   },
   {
    "duration": 227,
    "start_time": "2022-09-08T18:08:13.992Z"
   },
   {
    "duration": 5,
    "start_time": "2022-09-08T18:08:15.503Z"
   },
   {
    "duration": 5883,
    "start_time": "2022-09-08T18:08:16.248Z"
   },
   {
    "duration": 11,
    "start_time": "2022-09-08T18:08:31.952Z"
   },
   {
    "duration": 23,
    "start_time": "2022-09-08T18:08:33.813Z"
   },
   {
    "duration": 10,
    "start_time": "2022-09-08T18:08:34.726Z"
   },
   {
    "duration": 10042,
    "start_time": "2022-09-08T18:08:35.581Z"
   },
   {
    "duration": 66291,
    "start_time": "2022-09-08T18:08:51.616Z"
   },
   {
    "duration": 119,
    "start_time": "2022-09-08T18:09:57.909Z"
   },
   {
    "duration": 0,
    "start_time": "2022-09-08T18:09:58.029Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-08T18:14:54.596Z"
   },
   {
    "duration": 72882,
    "start_time": "2022-09-08T18:14:59.049Z"
   },
   {
    "duration": 42105,
    "start_time": "2022-09-08T18:16:12.001Z"
   },
   {
    "duration": 11,
    "start_time": "2022-09-08T18:17:30.716Z"
   },
   {
    "duration": 353521,
    "start_time": "2022-09-08T18:17:45.589Z"
   },
   {
    "duration": 42006,
    "start_time": "2022-09-08T18:23:39.201Z"
   },
   {
    "duration": 1192300,
    "start_time": "2022-09-08T18:24:21.208Z"
   },
   {
    "duration": 61206,
    "start_time": "2022-09-08T18:44:13.510Z"
   },
   {
    "duration": 1191925,
    "start_time": "2022-09-08T18:45:14.718Z"
   },
   {
    "duration": 11,
    "start_time": "2022-09-08T19:05:06.645Z"
   },
   {
    "duration": 7,
    "start_time": "2022-09-08T20:07:34.663Z"
   },
   {
    "duration": 8,
    "start_time": "2022-09-08T20:07:43.436Z"
   },
   {
    "duration": 25750,
    "start_time": "2022-09-08T20:52:25.951Z"
   },
   {
    "duration": 1673,
    "start_time": "2022-09-09T19:18:20.595Z"
   },
   {
    "duration": 3280,
    "start_time": "2022-09-09T19:18:22.270Z"
   },
   {
    "duration": 29,
    "start_time": "2022-09-09T19:18:25.551Z"
   },
   {
    "duration": 12,
    "start_time": "2022-09-09T19:18:25.582Z"
   },
   {
    "duration": 228,
    "start_time": "2022-09-09T19:18:25.595Z"
   },
   {
    "duration": 5,
    "start_time": "2022-09-09T19:18:25.824Z"
   },
   {
    "duration": 7,
    "start_time": "2022-09-09T19:18:25.831Z"
   },
   {
    "duration": 6016,
    "start_time": "2022-09-09T19:18:25.839Z"
   },
   {
    "duration": 10,
    "start_time": "2022-09-09T19:18:31.856Z"
   },
   {
    "duration": 36,
    "start_time": "2022-09-09T19:18:31.868Z"
   },
   {
    "duration": 11,
    "start_time": "2022-09-09T19:18:31.905Z"
   },
   {
    "duration": 164,
    "start_time": "2022-09-09T19:18:31.917Z"
   },
   {
    "duration": 71,
    "start_time": "2022-09-09T19:18:32.754Z"
   },
   {
    "duration": 57,
    "start_time": "2022-09-09T19:18:33.484Z"
   },
   {
    "duration": 58,
    "start_time": "2022-09-09T19:18:33.946Z"
   },
   {
    "duration": 483,
    "start_time": "2022-09-09T19:18:34.435Z"
   },
   {
    "duration": 9,
    "start_time": "2022-09-09T19:18:34.938Z"
   },
   {
    "duration": 1077,
    "start_time": "2022-09-09T19:18:35.439Z"
   },
   {
    "duration": 431,
    "start_time": "2022-09-09T19:21:29.609Z"
   },
   {
    "duration": 10,
    "start_time": "2022-09-09T19:21:31.158Z"
   },
   {
    "duration": 1459,
    "start_time": "2022-09-09T19:21:43.759Z"
   },
   {
    "duration": 798,
    "start_time": "2022-09-09T19:21:57.139Z"
   },
   {
    "duration": 31,
    "start_time": "2022-09-09T19:21:58.008Z"
   },
   {
    "duration": 13,
    "start_time": "2022-09-09T19:22:21.501Z"
   },
   {
    "duration": 216,
    "start_time": "2022-09-09T19:22:22.296Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-09T19:22:23.287Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-09T19:22:25.863Z"
   },
   {
    "duration": 5932,
    "start_time": "2022-09-09T19:22:42.466Z"
   },
   {
    "duration": 10,
    "start_time": "2022-09-09T19:22:54.237Z"
   },
   {
    "duration": 26,
    "start_time": "2022-09-09T19:23:23.911Z"
   },
   {
    "duration": 11,
    "start_time": "2022-09-09T19:23:31.668Z"
   },
   {
    "duration": 192,
    "start_time": "2022-09-09T19:23:32.719Z"
   },
   {
    "duration": 60,
    "start_time": "2022-09-09T19:23:38.894Z"
   },
   {
    "duration": 59,
    "start_time": "2022-09-09T19:23:43.767Z"
   },
   {
    "duration": 57,
    "start_time": "2022-09-09T19:23:46.892Z"
   },
   {
    "duration": 4,
    "start_time": "2022-09-09T19:54:12.743Z"
   },
   {
    "duration": 1467,
    "start_time": "2022-09-09T19:54:18.288Z"
   },
   {
    "duration": 816,
    "start_time": "2022-09-09T19:54:19.757Z"
   },
   {
    "duration": 33,
    "start_time": "2022-09-09T19:54:20.575Z"
   },
   {
    "duration": 14,
    "start_time": "2022-09-09T19:54:20.677Z"
   },
   {
    "duration": 232,
    "start_time": "2022-09-09T19:54:21.158Z"
   },
   {
    "duration": 7,
    "start_time": "2022-09-09T19:54:21.635Z"
   },
   {
    "duration": 9,
    "start_time": "2022-09-09T19:54:22.353Z"
   },
   {
    "duration": 6058,
    "start_time": "2022-09-09T19:54:23.115Z"
   },
   {
    "duration": 11,
    "start_time": "2022-09-09T19:54:29.175Z"
   },
   {
    "duration": 26,
    "start_time": "2022-09-09T19:56:50.832Z"
   },
   {
    "duration": 12,
    "start_time": "2022-09-09T19:56:51.551Z"
   },
   {
    "duration": 283,
    "start_time": "2022-09-09T19:56:52.235Z"
   },
   {
    "duration": 6275,
    "start_time": "2022-09-09T19:58:02.836Z"
   },
   {
    "duration": 72562,
    "start_time": "2022-09-09T19:59:56.016Z"
   },
   {
    "duration": 77836,
    "start_time": "2022-09-09T20:02:04.831Z"
   },
   {
    "duration": 44521,
    "start_time": "2022-09-09T20:03:22.669Z"
   },
   {
    "duration": 356275,
    "start_time": "2022-09-09T20:04:07.193Z"
   },
   {
    "duration": 40791,
    "start_time": "2022-09-09T20:10:03.470Z"
   },
   {
    "duration": 1237040,
    "start_time": "2022-09-09T20:10:44.263Z"
   },
   {
    "duration": 62669,
    "start_time": "2022-09-09T20:31:21.305Z"
   },
   {
    "duration": 1231137,
    "start_time": "2022-09-09T20:32:23.976Z"
   },
   {
    "duration": 11,
    "start_time": "2022-09-09T20:52:55.115Z"
   },
   {
    "duration": 29684,
    "start_time": "2022-09-09T20:53:55.675Z"
   },
   {
    "duration": 1706,
    "start_time": "2022-09-10T12:25:26.922Z"
   },
   {
    "duration": 3208,
    "start_time": "2022-09-10T12:25:28.630Z"
   },
   {
    "duration": 34,
    "start_time": "2022-09-10T12:25:31.840Z"
   },
   {
    "duration": 15,
    "start_time": "2022-09-10T12:25:31.876Z"
   },
   {
    "duration": 259,
    "start_time": "2022-09-10T12:25:31.893Z"
   },
   {
    "duration": 13,
    "start_time": "2022-09-10T12:25:32.154Z"
   },
   {
    "duration": 9,
    "start_time": "2022-09-10T12:25:32.169Z"
   },
   {
    "duration": 6881,
    "start_time": "2022-09-10T12:25:32.180Z"
   },
   {
    "duration": 11,
    "start_time": "2022-09-10T12:25:39.063Z"
   },
   {
    "duration": 29,
    "start_time": "2022-09-10T12:25:39.076Z"
   },
   {
    "duration": 13,
    "start_time": "2022-09-10T12:25:39.106Z"
   },
   {
    "duration": 7250,
    "start_time": "2022-09-10T12:25:39.120Z"
   },
   {
    "duration": 72625,
    "start_time": "2022-09-10T12:25:46.372Z"
   },
   {
    "duration": 78089,
    "start_time": "2022-09-10T12:26:58.998Z"
   },
   {
    "duration": 45410,
    "start_time": "2022-09-10T12:28:17.089Z"
   },
   {
    "duration": 368399,
    "start_time": "2022-09-10T12:29:02.568Z"
   },
   {
    "duration": 44305,
    "start_time": "2022-09-10T12:35:10.969Z"
   },
   {
    "duration": 161,
    "start_time": "2022-09-10T12:36:26.605Z"
   },
   {
    "duration": 124743,
    "start_time": "2022-09-10T12:38:08.938Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
